
## Autores

- [GitHub: @Eliohanyp](https://github.com/Eliohanyp)
- [LinkedIn: Eliohan Yamauti Poiati](https://www.linkedin.com/in/eliohanyp/)


# Estudos de Machine Learning e Data Science

[Repositorio Criado em: 21/04/2022]

Este repositorio contar√° com notebooks de estudos e conhecimentos aplicados pelo Eliohan Yamauti Poiati, Todos os codigos e conhecimentos aplicados foram adquiridos no trabalho e de cursos que fiz com o passar dos anos.

O 1¬∫ Topico ser√° sobre Machine Learning e Data Science com PYTHON (Estudos_MachineLearning_01.ipynb)

Dentro deste notebook citado teremos diversas categorias e uma ordena√ß√£o do conteudo para um aprendizado completo.

# - [Estudos_MachineLearning_01.ipynb](https://colab.research.google.com/drive/1uyD39XFVo-tEezW6q58shNrX-BqAjCEU?usp=sharing)

üë®‚Äçüíª Notebook de estudos de Machine Learning com Python by Eliohan Y. Poiati üë®‚Äçüíª

Este notebook abordar√° primeiro sobre a tarefa de classifica√ß√£o da aprendizagem de m√°quina.

### CLASSIFICA√á√ÉO: 

üî∏ 1. Pr√©-processamento e prepara√ß√£o de bases de dados para classifica√ß√£oüî∏

üî∏ 2. Aprendizagem bayesiana (algoritmo Naive Bayes). üî∏

üî∏ 3. Aprendizagem por √°rvores de decis√£o (algoritmo b√°sico de √°rvores e Random Forest). üî∏

üî∏ 4. Aprendizagem por regras. üî∏

üî∏ 5. Aprendizagem baseada em inst√¢ncias (algoritmo kNN). üî∏

üî∏ 6. Regress√£o log√≠stica. üî∏

üî∏ 7. M√°quinas de vetores de suporte (SVM).üî∏

üî∏ 8. Redes neurais artificiais. üî∏

üî∏ 9. Avalia√ß√£o de algoritmos de classifica√ß√£o. üî∏

üî∏ 10. Combina√ß√£o e rejei√ß√£o de classificadores. üî∏

üìöBons Estudos!  üòâüòâüòâ

# üî∏ 1. Pr√©-processamento e prepara√ß√£o de bases de dados para classifica√ß√£oüî∏
üîß Pr√©-Processamento de Dados com Pandas e Scikit-Learn üîß

üî∏ O pr√© processamento serve para voce deixar as base de dados consistente para o machine learning.

üî∏ Ser√£o usados uma base de dados de Cr√©dito e Censo.

üî∏ Para o pr√©processamento utilizaremos valores inconsistentes e valores faltantes em nossa base para simular o maximo possivel os dados da vida real.

üî∏ Trabalharemos com escalonamento de atributos para deixar os valores numericos na mesma escala e tambem trabalharemos com transforma√ß√£o de variaveis categoricas.

üî∏ No PANDAS iremos usar varios recursos como: Localizar, remover linhas e colunas, alterar valores... 

üî∏ E para finalizar o modulo darei uma introdu√ß√£o de como avaliar o algoritmo e como separar base de treino e base de teste.

## Tipos de variaveis

![TIpos de variaveis](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/f512f68879c14b9d3013a8a9b9fef3b7ff07356d/Images_ML-DS/Tipos%20de%20Vari%C3%A1veis.PNG)

## Importa√ß√£o e instala√ß√£o das bibliotecas
#### Instala√ß√£o das bibliotecas utilizadas

```bash
!pip install pandas seaborn matplotlib numpy
!pip -q install plotly --upgrade
!pip -q install yellowbrick
```
#### Importa√ß√£o das bibliotecas utilizadas

```bash
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
```
### Explora√ß√£o de Dados
#### Base de dados de cr√©dito 

 * Fonte (adaptado): https://www.kaggle.com/laotse/credit-risk-dataset

Baixe a base de dados e fa√ßa upload para sua maquina ou Google Colab

Leia o arquivo .csv com o Pandas utilizando: 
```bash
base_credito = pd.read_csv('credit_risk_dataset.csv')
```
Para visualizar alguns registros, s√≥ chamar a base de credito:
```bash
base_credito
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Base_credito.PNG)

Podemos observar que s√£o 32.581 linhas e 12 colunas, agora iremos fazer uma analise b√°sica da nossa base de dados.

Se quisermos ver o 10 primeiros podemos usar .head()
```bash
base_credito.head(10)
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Base_credito_head.PNG)

Se quisermos ver o 10 ultimos podemos usar .tail()
```bash
base_credito.tail(10)
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Base_credito_tail.PNG)

Se quisermos a informa√ß√£o das colunas e seus tipos .info()
```bash
base_credito.info()
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Base_credito_info.PNG)

Se quisermos uma analise rapida podemos usar o .describe()
```bash
base_credito.describe()
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Base_credito_describe.PNG)

Se queremos ativar um filtro especifico podemos fazer assim: 
```bash
base_credito[base_credito['person_age'] >= 90]
```
Dessa forma ir√° aparecer somente quem tiver com idade acima de 90
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Base_credito_idade.PNG)

### Visualiza√ß√£o de Dados
#### Base de dados de cr√©dito 
Leia o arquivo .csv com o Pandas utilizando: 
```bash
base_credito = pd.read_csv('credit_risk_dataset.csv')
```
agora iremos usar a biblioteca NumPy e utilizaremos a fun√ß√£o .unique([]) que mostra os valores unicos da coluna que for especificada
```bash
np.unique(base_credito['cb_person_default_on_file'])
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/np_unique.PNG)

E se queremos saber quantos foram 'N' e quantos foram 'Y' podemos adicionar um return_counts=True assim:
```bash
np.unique(base_credito['cb_person_default_on_file'], return_counts=True)
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/np_unique_count.PNG)

Assim conseguimos observar que temos 26.836 'N' e 5.745 'Y'.


Podemos plotar isso em um grafico com o Seaborn:
```bash
sns.countplot(x = base_credito['cb_person_default_on_file']);
```
![Base de Cr√©dito](https://raw.githubusercontent.com/Eliohanyp/Ciencia_de_Dados/main/Images_ML-DS/Grafico.PNG)

Assim conseguimos observar em um histograma com o resultado
